% -----------------------------------------------------------------------------%
% Title:                                                                       %
% Author: Jan Ian Failenschmid                                                 %
% Created Date: 13-03-2024                                                     %
% -----                                                                        %
% Last Modified: 24-08-2024                                                    %
% Modified By: Jan Ian Failenschmid                                            %
% -----                                                                        %
% Copyright (c) 2024 by Jan Ian Failenschmid                                   %
% E-mail: J.I.Failenschmid@tilburguniveristy.edu                               %
% -----                                                                        %
% License: GNU General Public License v3.0 or later                            %
% License URL: https://www.gnu.org/licenses/gpl-3.0-standalone.html            %
% -----------------------------------------------------------------------------%

\documentclass[man, floatsintext]{apa7}

% Dependencies
\usepackage{csquotes, amsmath, amssymb, mathptmx, enumitem}
\usepackage[american]{babel}
\usepackage[style=apa,sortcites=true,sorting=nyt,backend=biber]{biblatex}
\DeclareLanguageMapping{american}{american-apa}
\graphicspath{ {./figures} } % Gaphics Path
\addbibresource{bibliography.bib} % Literature bibliography
\addbibresource{R_bib.bib} % R bibliography

% Title Page
\title{Modeling Non-Linear Psychological Processes: Reviewing and Evaluating
  (Non-) parametric Approaches and Their Applicability to Intensive
  Longitudinal
  Data}

\shorttitle{Modelling Non-Linear Psychological Processes}

\leftheader{Failenschmid}

\authorsnames{{Jan I. Failenschmid}, {Leonie V.D.E Vogelsmeier}, {Joris
      Mulder}, {Joran Jongerling}}

\authorsaffiliations{{Tilburg University}}

\abstract{Here could your abstract be!}

\keywords{Here could your keywords be!}

\authornote{
  \addORCIDlink{Jan I. Failenschmid}{0009-0007-5106-7263}

  Correspondence concerning this article should be addressed to Jan I.
  Failenschmid, Tilburg School of Social and Behavioral Sciences: Department of
  Methodology and Statistics, Tilburg University, Warandelaan 2, 5037AB
  Tilburg,
  Netherlands.	E-mail: J.I.Failenschmid@tilburguniversity.edu}

\begin{document}

\maketitle

Psychological constructs are increasingly viewed as components of complex
dynamic systems \parencite{nesselroade_studying_2004, wang_investigating_2012}.
This perspective emphasizes that these constructs fluctuate over time and
within
individuals. To study these variations and the underlying processes,
researchers are increasingly collecting intensive longitudinal data (ILD) using
ecological momentary assessment (EMA), experience sampling, or similar methods
\parencite{fritz_so_2023}. In
these studies several individuals are assessed at a high
frequency (up to multiple times per day) using brief questionnaires or
passive measurement devices. This rich data allows researchers to examine
variations in latent psychological variables within an ecologically valid
context and to explain them through (between-person differences)
in within-person processes.

Many non-linear psychological phenomena and processes have been discovered
during the
recent years. Clear examples of this are the learning and growth curves
observed in intellectual and cognitive development
\parencite{kunnen_dynamic_2012, mcardle_comparative_2002}. In these cases, an
individual's latent ability increases over time from a (person specific)
starting point towards an (person specific) asymptote,
which reflects their maximum ability. Additional examples of
asymptotic growth over the shorter time spans that are typically studied with
ILD include
motor skill development \parencite{newell_time_2001} and second language
acquisition \parencite{de_bot_dynamic_2007}. Figure~\ref{fig:examplar_npn}
illustrates these general growth curves through an exponential growth
function (a) and a logistic growth function (b), both of which are common
model choices for these kinds of processes.

\begin{figure}[!ht]
  \caption{Examples of non-linear processes demonstrated to occur in
    psychological time series.}
  \fitfigure{exemplar_no_process_noise.png}
  \figurenote{This figure shows four demonstrated psychological non-linear
    processes. Panels (a) and (b) show exponential and logistic growth curves,
    respectively, which have been shown to describe intellectual and cognitive
    development \parencite{kunnen_dynamic_2012,mcardle_comparative_2002},
    motor skill learning \parencite{newell_time_2001}, and second language
    acquisition \parencite{de_bot_dynamic_2007}. Panel (c)
    shows a cusp model from catastrophe theory that exhibits apparent jumps
    between two stable states. As such, it has been used to describe the
    perception of mental flow \parencite{ceja_suddenly_2012} or alcohol use
    relapse \parencite{witkiewitz_modeling_2007}.
    Lastly, panel (d) shows a damped oscillator, which describes
    the return of a perturbed system to baseline, which has been proposed as a
    model for affect regulation \parencite{chow_emotion_2005}.}
  \label{fig:examplar_npn}
\end{figure}

Another commonly observed non-linear phenomenon involves the construct under
study switching between multiple distinct states, which often
correspond to different
means. This occurs, for example, during the sudden perception of cognitive
flow, where individuals abruptly switch from a `normal' state to a flow state
and back \parencite{ceja_suddenly_2012}. Another example is alcohol use
relapse, where patients suddenly switch from an abstinent state to a relapsed
state \parencite{witkiewitz_modeling_2007}. This sudden switching behavior is
exemplified in Figure~\ref{fig:examplar_npn}~(c)
through a cusp catastrophe model. This model, drawn from catastrophe
theory, naturally leads to mean level switches when varying one of its
parameters \parencite{van_der_maas_sudden_2003,chow_cusp_2015}.

As a final example, one may consider (self-) regulatory systems, which maintain
a desired state by counteracting external perturbations. These systems regulate
adaptively, meaning that the regulation strength depends on the distance
between the
current and desired states. The common autoregressive model describes such a
system in which the regulation strength depends linearly on this distance.
However, this relationship may also be non-linear, such that the
regulatory force increases disproportionately with larger mismatches. Such
(self-) regulatory models have been proposed to describe for example emotion
regulation
\parencite{chow_emotion_2005}.
Figure~\ref{fig:examplar_npn}~(d) illustrates a
(self-) regulatory system exemplified as a damped oscillator.

Although initial evidence for non-linearity in psychological research exists,
theories about the nature and form of non-linear psychological processes remain
scarce \parencite{tan_time-varying_2011}. This gap is largely due to the lack
of advanced statistical methods that are flexible enough to study the complex
behavior of these processes adequately. As a result, researchers are often
ill-equipped to infer the functional characteristics of non-linear processes
from ILD, which hinders the development and evaluation of guiding theories for
subsequent studies. Due to this lack of adequate available statistical methods,
non-linear trends are most often addressed in psychology through polynomial
regression or regression splines.

Polynomial regression \parencite{jebb_time_2015} uses higher-order terms
(e.g., squared or cubed time) as predictors in a standard multiple linear
regression model. While effective for relatively simple non-linear
relationships,
particularly those that can be represented as polynomials, this method has
significant limitations and likely leads to invalid results when applied to
more complex latent processes, such as mean switching or (self-) regulatory
systems (e.g., Figure~\ref{fig:examplar_npn}~c~\&~d). In these cases,
polynomial approximations require many higher-order
terms to capture the process's high variability, which raises the problem of
over- or underfitting the data, causes model instability, and leads to
nonsensical inferences (e.g., interpolating scores outside the scale range;
\textcite{boyd_divergence_2009,harrell_general_2001}).

An alternative approach is spline regression, which constructs a complex
non-linear trend by joining multiple simple piecewise functions at specific
points, called knots (e.g., combining multiple cubic functions into a growth
curve with plateaus; \textcite{tsay_nonlinear_2019}). However, spline
regression requires a careful, manual selection of the optimal piecewise
functions and
knot locations. This can be problematic in practice because, as mentioned,
precise guiding theories about the functional form of most psychological
processes are lacking \parencite{tan_time-varying_2011}. This absence of clear
guidance can easily lead to misspecified models and invalid results.

These limitations in current practices underscore the need for alternative
statistical methods to study non-linear processes. Various
such advanced statistical
methods, such as kernel regression, Gaussian processes, smoothing splines, and
latent change score models, are available outside of psychology. However, these
methods have rarely been applied in psychology because they have not been
reviewed for an applied audience, nor have their assumptions and inference
possibilities been evaluated in the context of ILD.\@ As a result,
psychological researchers struggle to select the most suitable method for a
specific context. This challenge is further complicated by the fact that the
ideal statistical method may depend on the characteristics of the underlying
non-linear process, which are generally unknown. Expecially, since the smooth
processes for which many of these methods were originally developed are
unlikely to occur in psychological research.

To address this important gap, this article reviews four advanced non-linear
analysis
methods and evaluates their applicability to typical ILD.\@ Specifically, we
compare how well each method can recover different latent processes under
common ILD conditions in a simulation study. We also demonstrate the
conclusions that can be drawn from each method by applying them to an existing
dataset. The methods reviewed in this article range from data-driven
non-parametric techniques to a flexible parametric modeling framework, which
were selected to accommodate varying degrees of prior knowledge, as
precise theories about the nature of non-linear psychological processes are
often missing \parencite{tan_time-varying_2011}. Further, to introduce these
methods accessibly and apply them under conditions where software
implementations are available, this article focuses primarily on the univariate
single-subject design.

\section{Method}

\subsection{Data structure}

Generally, any psychological construct under study follows a (possibly
non-linear) function over time, as represented by the lines in Figure 1.
However, since these psychological processes are typically unobservable or
latent, they are measured through observable indicators, such as questionnaire
items or passive measurements. The observations on these indicators
(Figure~\ref{fig:examplar_npn}, dots)
differ from the true values of the latent process due to measurement
error, which may come from an imperfect measurement instrument.
For this introduction, we assume that all time-point-specific measurement
errors are independent and normally distributed. The model for the
observations of a single indicator can then be written as:

\begin{align}
  Y_t = f(t) + \epsilon_t; \quad \epsilon_t \sim N(0, \sigma^2_{\epsilon})
\end{align}

\noindent where $f(t)$ represents the potentially non-linear latent process,
and $\epsilon_t$ represents the time-point-specific measurement error.

In this context, researchers typically aim to infer the underlying process and
draw conclusions about its functional form. The following sections will
introduce four methods to achieve these goals, two non-parametric techniques,
one semi-parametric approach, and one parametric modeling framework, using the
(self-) regulatory process depicted in Figure~\ref{fig:examplar_npn}~(d)
as a running example.

\subsubsection{Local polynomial regression}

The first technique is called local polynomial regression (LPR). Similarly to
regular polynomial regression, LPR approximates the process using polynomial
basis functions (e.g., squared or cubed time). However, instead of using one
large polynomial to approximate the entire process, LPR estimates smaller,
local polynomials at each point in time. These local polynomials are then
combined into a single non-linear function over the entire set of observations
\parencite{fan_adaptive_1995, ruppert_multivariate_1994, fan_local_2018}.

To determine the value of the LPR at a specific time point, the data is
centered around that point (by shifting the data along the time axis so
that the chosen time point is at zero), and a low-order polynomial is fitted
around it. Additionally, to account for the idea that data points closer in
time are more related, a weighting function is applied during the polynomial
estimation. This function assigns weights to each data point based on its
distance from the point of interest. The value of the LPR at the chosen
time point is then given, by the intercept of the locally weighted polynomial.
To find the LPR value at a different time
point, the same procedure is repeated, centering the data around the new point
of interest. Since it is theoretically possible to repeat this process at
infinitely many
time points, LPR is a non-parametric technique. Figure~\ref{fig:locpol_dem}
shows the estimated LPR for the example process depicted in
Figure~\ref{fig:examplar_npn}~(d).  In this figure, three truncated examples of
local cubic regressions are shown
in red, which contribute to the overarching LPR for this process .\@

\begin{figure}[!ht]
  \caption{Demonstration of how local polynomial regression (solid black)
    estimates the underlying process (dotted black). Here, three local cubic
    functions (red) are shown as examples at the time points 50, 100, and 150,
    which provide the values of the local polynomial regression at these time
    points.}
  \fitfigure{locpol_demonstration.png}
  \label{fig:locpol_dem}
\end{figure}

When fitting an LPR, several decisions must be
made regarding the degree of the local polynomials and the optimal weighting of
the data. Typically, the degree of these local polynomials is kept low and odd.
This choice reflects a bias-variance tradeoff, where higher-order polynomials
reduce bias but increase variance, when transitioning from an odd
to an even power \parencite{ruppert_multivariate_1994}. The data weighting
in an LPR is achieved through a
kernel function, which is usually centered and symmetric to assign weights
based
on the distance from the origin. Common kernel choices include the Gaussian and
symmetric Beta distributions. However, most commonly used kernel functions
yield similar
inferences and a specific kernel can be selected to minimize a chosen criterion
function. The kernel is further defined by a bandwidth
parameter, which determines its width and effectively controls the influence of
more distant data points. The bandwidth parameter, in practice, represents the
wiggliness of the estimated process.
Several methods are available to find the optimal bandwidth by optimizing a
data-dependent criterion function, such as cross-validation or the mean
integrated squared error \parencite{kohler_review_2014, debruyne_model_2008}.

Due to its non-parametric nature, LPR makes minimal assumptions about the data.
However, it does require that the underlying process is smooth or
differentiable, which is
a necessary condition for polynomial approximation.
Another key assumption is that the process has constant
wiggliness, represented by a single bandwidth parameter. However,
this assumption may be relaxed by using a time-varying bandwidth.

\subsubsection{Gaussian process regression}

The second non-parametric technique is Gaussian process (GP) regression, a
Bayesian approach that directly defines a probability distribution over an
entire family of non-linear functions flexible enough to capture many complex
processes effectively \parencite{rasmussen_gaussian_2006,
  betancourt_robust_2020, roberts_gaussian_2013}. Unlike regular probability
distributions (e.g., normal distributions) that specify the plausibility of
single values, Gaussian processes determine the plausibility of entire
(non-linear) functions. In a Bayesian framework, one can use a GP to define
a prior distribution for the latent process. This prior is then combined
with an appropriate likelihood for the observed data to obtain a posterior
distribution for the latent process given the observed data.
This posterior distribution represents an updated belief about which functions
describe the latent process well, allowing one to draw inferences about the
process itself. Figure~\ref{fig:gp_dem} illustrates such a posterior
distribution for the running
example process. The red lines represent a sample of non-linear functions
drawn from the posterior distribution, with the pointwise average of these
functions providing a mean estimate for the underlying process.

\begin{figure}[!ht]
  \caption{Demonstration of how Gaussian process regression estimates the
    underlying process (dotted black). Here, a sample of functions drawn from
    the
    posterior Gaussian process probability distribution is shown (red). The
    predicted value for the underlying process is then obtained by averaging
    the
    drawn functions.}
  \fitfigure{gp_demonstration.png}
  \label{fig:gp_dem}
\end{figure}

The GP prior is parameterized by a mean function and a covariance function,
which are continuous extensions of the mean vector and covariance matrix of a
multivariate normal distribution. These functions can be selected based on
domain knowledge or through data-driven model selection
\parencite{richardson_gaussian_2017, abdessalem_automatic_2017}. In practice,
the mean function is often set to zero when no specific prior knowledge is
available, which does not constrain the posterior mean to zero but instead
indicates a lack of prior information about its deviations from zero.
The covariance function is typically based on a kernel function, which assigns
covariances between time points only depending on their distance
(e.g., quadratic exponential, Matern class). Finally, appropriate hyperpriors
for the parameters of the mean and covariance functions are used to generate
the corresponding posterior distribution. These hyperpriors reflect
prior beliefs about the hyperparameters and can be used to constrain them to
sensible values.

The functional behavior of a GP is entirely determined by the posterior mean
and covariance function. Thus, to accurately capture a process, it is crucial
that the functional familiy generated by a chosen mean and covariance function
is similar to the actual process.
Common choices for the covariance function result in smooth and
covariance-stationary GPs with constant wiggliness. Unlike LPR, GP
regression provides more interpretable information about the process through
the posterior distributions of the hyperparameters.
One typical hyperparameter, the characteristic length scale of the covariance
function, is analogous to the bandwidth parameter in LPR, as it also describes
the wiggliness of the estimated process. However, GP regression can
include additional hyperparameters, allowing for more specific theories to be
tested through model comparison.

\subsubsection{Generalized additive models}

Generalized additive models (GAM) are a semi-parametric modeling framework
that builds on smooth terms, which are non-linear functions
that are inferred from the data through
smoothing splines \parencite{wood_generalized_2006, wood_inference_2020,
  hastie_generalized_1999}. Smoothing splines are an extension of the regular
spline
regression introduced above, which circumvent the knot placement issue by
placing a knot at each
observation \parencite{tsay_nonlinear_2019}. This is equivalent to a
basis function regression with as many basis functions as there are
observations. However, using this many knots usually leads to overfitting. To
prevent this, smoothing splines use a penalty term, similar to the penalty
used in a lasso or ridge regression, which controls the smooth term's
wigglyness
\parencite{gu_smoothing_2013, wahba_spline_1980}. This penalty makes it
possible to balance the flexibility and fitting of the smooth term,
ensuring that the model captures the process
accurately without excessive complexity. In practice, the optimal weight of the
penalty is
determined by minimizing a criterion function, such as the generalized
cross-validation criterion \parencite{wood_generalized_2006,
  golub_generalized_1997}. While researchers must still choose a set of basis
functions, cubic \parencite{tsay_nonlinear_2019} and thin plate spline bases
\parencite{wood_thin_2003} are optimal for many applications.

These smooth terms can then be combined in an additive regression model, where
each smooth term essentially functions as a predictor within a regular
regression
analysis. In this model, smooth terms may be multiplied by covariates and
summed into a single overall non-linear function to explain the data. This
approach makes it possible to formulate models such as a time-varying
autoregressive model, where the intercept and autoregressive parameters are
smooth terms of time \parencite{bringmann_changing_2017,
  bringmann_modeling_2015}. By integrating non-parametric smooth terms into a
broader parametric model, GAMs become semi-parametric models that are
well-suited for testing specific hypotheses while keeping the flexibility
needed to accurately capture the latent process. Figure~\ref{fig:gam_dem}
illustrates a simple GAM with a single smooth term for time, fitted to the
example process. Some of the scaled thin-plate smoothing spline basis
functions that make up the smooth term are shown in red.

\begin{figure}[!ht]
  \caption{Demonstration of how generalized additive models (solid black)
    estimate the underlying process (dotted black). Here, the predicted values
    for the process at any point in time correspond to the weighted average of
    the basis functions (red).}
  \fitfigure{gam_demonstration.png}
  \label{fig:gam_dem}
\end{figure}

Compared to the previous methods, GAMs offer a more accessible modeling
framework,
enabling the specific modeling and testing of partial theories. For instance, a
GAM can model a linear trend with an added smooth term around it to capture
non-linear deviations. This makes it possible to gain insight into both
the linear trend and the necessity of the smooth term, which may be examined
through model comparison.
Additionally, GAMs also provide an estimate of the wigglyness
of the process through the weight that is assigned to the smoothing penalty.
In contrast, to LPR and GP
this penalty weight does not assume constant wigglyness. Lastly, the
basis fu,nction coefficients within each smooth term can be interpreted,
but the specific interpretations depend on the spline basis used.

\subsubsection{Parametric models}

Finally, several methods to parametrically model non-linear processes will be
introduced. The most direct approach for this involves defining a non-linear
regression model for the process itself. As with all parametric models,
this approach requires a thorough
prior theory about the functional form of the process, which is often difficult
or even impossible to find in practice due to the
complexity of the underlying dynamic systems.
However, in the case of the running example, such a formulation exists.
Due to the oscillatory nature of this (self-) regulatory process,
a cosine function is a natural candidate to model it.
Additionally, to account for the oscillations diminishing over time,
the model needs to describe a decreasing amplitude. An example of such a
model is:

\begin{equation}
  \begin{aligned}
    f(t)   & = A e^{-c t} \cos(\omega t - \delta) \\
    \omega & = \sqrt{k - \frac{c^2}{4}}
  \end{aligned}
\end{equation}

\noindent where the parameters control the initial amplitude of the wave
function ($A$),
the frequency ($\omega$), the rate at which the amplitude decreases ($c$), and
the phase ($\delta$). Even for this relatively simple system, this parametric
form is already quite complex and for more intricate processes, finding an
appropriate model of this form can be nearly impossible.

Instead it is often more practical to define a model for how a process changes
over
time using a differential equation model \parencite{cooper_dynamical_2012}.
These models describe the relationship between the current value of the process
and its instantaneous rate of change. By combining a model of the process's
change with information about its initial state, it is then possible to infer
the entire trajectory of the process. Thus,
differential equations form a general class of models capable of representing
various dynamic processes. For the running example, we used a damped oscillator
model. This is a classic differential equation model originally designed to
describe the
behavior of an oscillating spring with resistance. This model can be expressed
as:

\begin{equation}
  \begin{aligned}
    \frac{\partial f}{\partial t} & = v         \\
    \frac{\partial v}{\partial t} & = -cv + -kf
  \end{aligned}
\end{equation}

\noindent This model relates the rate of change of the position of the spring
$f$ to
its velocity $v$. In turn, the rate of change of the velocity is determined
by the velocity itself through the damping coefficient $c$ and by the
position of the spring through the spring constant $k$. Here, the spring
constant is related to the frequency of the oscillations since a stiffer
spring oscillates faster and the damping coefficient is related to how quickly
the spring returns to its basis position after being perturbed.
\textcite{chow_emotion_2005} show how this model can be applied in a
psychological context to model emotional self-regulation. Such that a perturbed
emotional state is regulated back to the desired baseline faster the larger
the perturbation is. % This is not super accurate is it now. 

Alternatively, when working with equally spaced time points, one can model
dynamic local changes in discrete time using difference equations
\parencite{durbin_time_2012}. These equations express the current value of the
latent construct as a function of its previous value.
A common example of this approach is the classic
autoregressive model. While the smooth nature of the running
example process cannot be perfectly captured by difference equations, it can be
approximated by these equations:

\begin{equation}
  \begin{aligned}
    f_{t} & = f_{t-1} + v_{t-1}        \\
    v_{t} & = (1-c)v_{t-1} + -kf_{t-1}
  \end{aligned}
\end{equation}

Lastly, when modeling a process through local dynamics, two types of errors
should be taken into account. The first is dynamic error, which describes any
external perturbations
to the latent construct that are carried forward over time. For instance,
if a participant experiences an unusually pleasant conversation that elevates
their true positive affect, this change represents an error effect if it is
not accounted for by the model. However, since the true
positive affect level has increased, this will influence future measurements
due to emotional inertia. Dynamic errors can be incorporated into the model in
different ways, but the most common approach is to add a normally
distributed error term to the deterministic dynamic change models described
above.

The second type of error that should be considered is measurement error,
which represents the difference between observed measurements and the
latent construct values, which may be introduced by an imperfect measurement
instrument. These errors are typically
modeled using a factor or item response model that links the observations to
the latent construct. Combining a dynamic change model with a dynamic error
component and a factor model yields a state space model \parencite[discrete
  time;][]{durbin_time_2012} or a stochastic differential equation model
(continuous time). These models can then be used to infer the process and
estimate the parameters of the dynamic equations using the Kalman filter and
its extensions \parencite{chow_unscented_2007}.

\section{Simulation}

\subsection{Problem}

A simulation study was conducted to assess the effectiveness of the introduced
parametric and non-parametric methods in recovering different
non-linear processes, which may be encountered in EMA research
(Figure~\ref{fig:examplar_npn}).
To apply the methods under the conditions described in the
introduction,
and within the constraints of available software implementations,
the simulation focused on
a univariate single-subject design. Hence, the simulated data represented
repeated measurements of a single variable for one individual.

\subsection{Design and Hypotheses}

For the non-parametric analysis methods (i.e., LPR, GP), we expect that
each method in its default configuration will most accurately infer processes
that are (a) continuous (i.e., without sudden jumps), (b) have constant
wigglyness (i.e., constant second derivative), and (c) are smooth (i.e.,
differentiable). We expect this, because both methods by default
produce
continuous, smooth estimates with a single constant bandwidth or lengthscale.
For the GAMs, we expect that only criteria (a) and (c) will influence
the performance, as GAMs do not assume constant wigglyness. The
parametric modeling approach is expected to provide the most accurate
inferences, serving as a benchmark for comparison with the other methods. We
also expect that the performance of parametric models will decrease as the
model complexity increases (e.g., with jumps or reduced smoothness), though
likely less so than with non-parametric and semi-parametric models.
Additionally, we expect that larger sample sizes will lead to more accurate
inferences, with both (d) the overall length of the sampling period and (e) the
sampling frequency being varied.

To conduct the simulation with processes that might be encountered in real
EMA studies, we selected the exemplar processes illustrated in
Figure~\ref{fig:examplar_npn} as a basis.
These include two growth curves, modeled as an exponential and
a logistic growth curve, a mean-level switching process, modeled as a cusp
catastrophe, and a self-regulatory process, represented by a damped oscillator.
These processes make it possible to test the impact of (a) sudden jumps and
(b) changing wigglyness on the four methods.
First, we hypothesize that the cusp catastrophe model, which is the only
process featuring jumps, will be least accurately inferred by all methods.
Second, all four processes exhibit changes in wigglyness (i.e., changes in the
second derivative) over time. However, while the wiggliness of the exponential
and logistic growth functions and the damped oscillator decreases
monotonically, the cusp catastrophe's wigglyness changes cyclically.
Therefore, we hypothesize that longer sampling periods for the exponential and
logistic
growth curves and the damped oscillator will reduce the inference accuracy of
the LPR and the GP, as the single bandwidth or lengthscale
parameter becomes increasingly inadequate to capture the changing
wigglyness over time. We do not expect this effect to occur for the cusp
catastrophe process, or when using GAMs or parametric models.

To manipulate the (c) smoothness of the processes, a dynamic noise
component was added to the data-generating models. This perturbed the
processes at each point in time by a normally distributed error,
resulting in non-smooth (i.e., non-differentiable or rough) trajectories.
The degree of roughness was controlled
by the variance of these dynamic errors and we considered variances of
0.5, 1, and 2 reasonable relative to the process range.
Figure~\ref{fig:exemplar_pn}
illustrates one possible realization of the exemplar processes with dynamic
noise. Importantly, we intentionally omitted a condition without dynamic noise
from this simulation, as dynamic noise is reasonably expected to be present in
all psychological intensive longitudinal data (ILD).

\begin{figure}[!ht]
  \caption{One possible realization of the non-linear exemplar processes
    with dynamic errors}
  \fitfigure{exemplar_process_noise.png}
  \label{fig:exemplar_pn}
\end{figure}

Additionally, the sample size was varied during the simulation by manipulating
both (d) the sampling period and (e) the sampling frequency, as these distinct
methodological
choices are expected to impact the performance of the analysis methods
differently. Specifically, for the LPR and the GP, which rely only on data in
local neighborhoods during the estimation, we expected that extending the
sampling period beyond this
neighborhood will not increase the inference accuracy.
In fact, if the process exhibits
changing wigglyness over the extended period, as previously discussed,
increasing the sampling period might even negatively affect the inference
accuracy. In contrast, we expeced GAMs and parametric models, which incorporate
the entire dataset in their estimations, to perform better with a longer
sampling period. Since there is no inherent scaling to the time axis in this
simulation, we chose to simulate the first half of each process in one
condition and the full process in another, referred to as sampling periods of
one or two weeks. This scaling is arbitrary and could be changed to any time
frame. Lastly, we expected that increasing the sampling frequency will
generally improve the inference accuracy across all methods, as it provides
more information about the latent processes.
We tested sampling frequencies of three, six, and nine measurements per day,
to align these choices with typical experience sampling study designs
\parencite{wrzus_ecological_2023}.

\subsection{Procedure}

To simulate the data, each exemplar process was represented as a generative
stochastic differential equation model. This means that, at each time point,
the rate of change of the
process was determined by a (non-linear) function of its current value combined
with an
additive dynamic error component modeled by a Wiener process. Data from these
generative models were then simulated using the Euler-Maruyama method.
This method draws samples from stochastic differential equation
models with an arbitrary degree of accuracy, while making it possible to
manipulate the sampling frequency and dynamic error variance.
Measurement errors were added later to the latent process data at
each time point from a standard normal distribution, generating the final sets
of observations. For a detailed technical explanation of the data generation
process, see Appendix A.

To determine the required number of data sets per condition, a
power simulation was conducted
based on an initial pilot sample of 30 generated data sets per
condition. Based on the pilot sampel, the outcome measures
(e.g., MSE, GCV, and confidence interval coverage scores) and their
corresponding standard deviations were calculated by condition.
These standard deviations were then used to
predict the Monte Carlo standard errors of the means of each outcome measure
across increasing sample sizes. These Monte Carlo standard errors reflect the
expected variation in the outcome statistics due to random processes within the
simulation. We selected the number of data sets per condition for the full
simulation, so that the
maximum expected Monte Carlo error across all outcome measures
and conditions was 0.05. This criterion was met with \textbf{N} data sets per
condition.

\subsection{Model estimation}

After simulating the data, all introduced methods were applied to each data set
using the statistical software R \parencite{R-base}. First, the LPR was
estimated using the nprobust package \parencite{R-nprobust}, which allows to
correction for the bias inherent in LPRs. Second, GPs were estimated in STAN
\parencite{R-cmdstanr} with a zero mean and a squared exponential covariance
function, following common practice. Third, GAMs with a single smooth term for
time were fitted using the MGCV package \parencite{R-mgcv_a}. Finally,
parametric differential equation models corresponding to the true
data-generating models were created and estimated using the Dynr package
\parencite{R-dynr}. While the same non-parametric models were used across all
conditions, the parametric models were tailored to each specific
data-generating process. After fitting each model to
the data, they were used to obtain point and interval estimates (i.e.,
95\% confidence and credible intervals) for the latent process at each time
point. A detailed description of each model fitting procedure
is provided in Appendix B.

To ensure reliable model fit and reasonable inferences, the fitting procedures
for each method were validated on pilot samples within each condition. After
this, an initial run of the simulation was performed, which revealed
that the GAMs over- or linearly underfit some data sets and that the parametric
models overfit some data sets. To prevent this, the fitting procedures of
both methods were adjusted and the simulation rerun. Further, if any
models failed to converge during the simulation, the corresponding outcome
measures were excluded from the following analyses.

\subsection{Outcome measures}

To evaluate and compare the performance of the different analysis methods, we
focused on three outcome measures. The first two assessed each method's
accuracy in predicting the process values at or between the observed time
points. These predictive accuracy measures indicate how well each method
captures the underlying non-linear process. The third outcome measure evaluated
the accuracy of the uncertainty estimates provided by each method.
Specifically, whether the confidence or credible intervals produced
by each method correctly included the true state value the expected proportion
of times.

\subsubsection{Capturing the non-linear process}

To assess how effectively each method captured the non-linear process at the
observed time points, we calculated the mean squared error (MSE) between the
estimated and generated process values. Additionally,
to evaluate how well each method
would predict unobserved process values within the process range, we computed
the generalized cross-validation (\parencite[GCV;][]{golub_generalized_1979})
criterion
for each method and data set. The GCV is a more computationally efficient and
rotation-invariant version of the ordinary leave-one-out cross-validation
criterion, with a similar interpretation. The latter is calculated by removing
one data point, refitting the
model while keeping certain parameters fixed, predicting the left-out
observation, and calculating the squared
prediction error. By repeating this procedure for each data point and averaging
the squared errors, leave-one-out cross-validation provides an estimate of
how accurately the model
predicts unobserved values within the design range.

Subsequently, two ANOVAs were conducted to analyze differences in MSE and GCV
values across simulation conditions and analysis methods. To simultaneously
identify both factors that likely
do and do not affect the MSE and GCV values, an exhaustive model search was
performed. In this search, AIC and BIC model weights were used to determine the
model, which provides the optimal balance between data fit and model
complexity. Notably, AIC weights can
be interpreted as conditional model probabilities when the true model is among
the tested models \parencite{wagenmakers_aic_2004}. The specific hypotheses
stated earlier
were tested using post hoc tests and marginal comparisons with appropriate
corrections for multiple comparisons.
Model assumptions were assessed on the final selected model. Given
the large sample sizes in this simulation, the ANOVAs were robust to moderate
violations of normality \parencite{blanca_non-normal_2017},
and any potential violations of homoscedasticity were
addressed using heteroscedasticity-consistent standard errors. However, if both
assumptions were severely violated, results were instead presented
descriptively, using means and standard errors for the respective conditions.

\subsubsection{Uncertainty quantification}

To evaluate the uncertainty estimates provided by each method, we recorded
whether the true generated process was located within the confidence or
credible intervals at each time point.
Subsequently, the average
confidence interval coverage proportion for each method and data set was
obtained, by averaging over all time points.
Given that all confidence or credible intervals were set at a
95\% confidence level, the expected coverage proportion should ideally be
close to 95\%. Due to Monte Carlo error in the simulation, average coverage
proportions between 93\% and 97\% were also deemed acceptable.
Average coverage proportions above 97\% suggested overestimated standard
errors,
while those below 93\% indicated either a poor approximation of the underlying
process or an underestimation of the standard errors.

\subsection{Results (Template)}

\subsubsection{Capturing the non-linear process}

For both outcome measures, the AIC and BIC model weights indicated the most
complex model, which included all interactions, as the best-fitting model with
a model weight of 1. Although the residuals for both models showed considerable
deviations from normality, characterized by being platykurtic, the residual
distributions were unimodal and approximately symmetric. Therefore, given the
large sample sizes in this simulation, the ANOVAs are expected to be robust
against these deviations. However, a Breusch-Pagan test indicated
heteroscedasticity in the residuals for both outcome measures, which was
subsequently corrected. After applying these corrections and using Bonferroni
adjustments for conducting two separate ANOVAs, the type-III ANOVA for MSE
revealed significant main and interaction effects, except for one four-way
interaction and the five-way interaction. The type-III ANOVA for the GCV values
indicated that all effects were significant. Although most higher-order
interactions had partial-$\eta^2$
values close to zero for both outcome measures.
Table \ref{tab:peta} presents the partial-$\eta^2$
values for all effects that showed at least a small effect size, highlighting
that the largest effects were associated with the main effects and interactions
that include the analysis method and the latent process. Therefore, the
following section will focus on analyzing these effects.
For a comprehensive overview of all effects in the model, see Appendix C.

\begin{table}[htbp]
  \vspace*{2em}
  \begin{threeparttable}
    \caption{All MSE and GCV ANOVA effects that have at least a small effect
      size in terms of the partial-$\eta^2$ (> 0.01)}
    \label{tab:peta}
    \begin{tabular}{@{}lrrr@{}} \toprule
      Factor                      & MSE partial-$\eta^2$ \\ \midrule
      Method                      & 0.65                 \\
      Process                     & 0.43                 \\
      Sampling period (SP)        & 0.07                 \\
      Sampling frequency (SF)     & 0.23                 \\
      Dynamic error variance (DE) & 0.47                 \\
      Method:Process              & 0.11                 \\
      Method:SP                   & 0.10                 \\
      Method:SF                   & 0.08                 \\
      Method:DE                   & 0.18                 \\
      Process:SF                  & 0.02                 \\
      Process:DE                  & 0.18                 \\
      SF:DE                       & 0.02                 \\
      Method:Process:SF           & 0.03                 \\
      Method:Process:DE           & 0.03                 \\ \midrule
    \end{tabular}
  \end{threeparttable}
\end{table}

Figure \ref{fig:results}~(a) shows the mean effect of different analysis
methods
for each process, averaged across sampling periods, frequency, and dynamic
error variances. As expected, the parametric models consistently show the
lowest MSE and GCV across
all processes. Among the semi- and non-parametric techniques, the GAM performed
the best in terms of MSE and GCV, followed by the LPR and the GP
infer the latent processes
with the least accuracy. Additionally, there are some differences in how
accurately both growth curves and the damped oscillator were inferred.
However, contrary
to our expectations, the cusp-catastrophe process was inferred with a lower MSE
and GCV by all methods.

\begin{figure}[!ht]
  \caption{Average MSE values illustrating the simulation results. Panel (a)
    shows the effect of the analysis methods for each latent process. The other
    three panels show the effects of measurement period (b), measurement
    frequency (c), and dynamic error variance (d) for each analysis method and
    latent process.}
  \fitfigure{results.png}
  \label{fig:results}
\end{figure}

The effect of the sampling period is illustrated in
Figure~\ref{fig:results}~(b), showing that extending the
sampling period from one to two weeks decreased the mean MSE and GCV values for
the parametric models and GAM, but increased these values for the LPR and
GP\@. This partially aligns with our expectations, as we predicted this effect
would be absent for the LPR and GP when inferring the cusp catastrophe model,
which is not supported by the data. Increasing the sampling frequency
(Figure~\ref{fig:results}~c)
generally led to lower mean MSE and GCV values, for all methods and
processes. Lastly, larger
dynamic error variances (Figure~\ref{fig:results}~d)
resulted in higher mean MSE and GCV values across all
processes and analysis methods, with this effect being least pronounced in the
cusp-catastrophe model.

\subsubsection{Uncertainty quantification}

Figure \ref{fig:ci_plot} shows the average confidence interval coverage
proportion
for each condition in the simulation. It can be seen that the only analysis
method which produces an average confidence interval coverage within
the prespecified accuracy interval of 93\% to 97\% is the parametric modelling.
All three non and semi-parametric analysis methods produced average
confidence interval coverages considerably below 93\%. However, among
these methods the average confidence interval coverages achieved by the GAM
are more accurate and more stable across the different conditions than the
coverages of the LPR and GP.

\begin{figure}[!ht]
  \caption{Average confidence interval coverage across all processes,
    analysis methods, and simulation conditions}
  \fitfigure{ci_plot.png}
  \label{fig:ci_plot}
\end{figure}

\section{An Empirical Example}

In the following, the four analysis methods previously introduced were
applied to depression data from the Leuven clinical study. This study used
experience sampling measures to study the dynamics of anhedonia in
individuals with major depressive disorder \parencite{heininga_dynamical_2019}.
This study was selected for its
heterogeneous sample, which includes participants with major depressive
disorder, borderline personality disorder, and healthy controls. This diversity
increases the likelihood of the data exhibiting a range of
(possibly non-linear) dynamics
and processes. Specifically, \textcite{houben_relation_2015}
found in their meta-analysis
that individuals with lower psychological well-being tend to experience greater
emotional variability, less emotional stability, and higher emotional inertia.
Although, this finding did not replicate in an analysis of positive affect
within the Leuven clinical study \parencite{heininga_dynamical_2019}.
Further, emotional
inertia, the extent to which an emotional state carries over across
time points, has been shown to vary within individuals over time, which makes
it likely that the processes underlying this data are non-stationary.
Lastly, this data also makes it possible to explore the previously
introduced theory that emotion regularion may work as a (self-) regulatory
system through parametic modelling.

To maintain consistency with how the methods were introduced and to avoid using
measurement models with multiple indicators, we analyzed momentary
depression, which was measured using a single item. This item was chosen over
affect measures because it displays sufficient variability, has a relatively
low proportion of participants with strong floor or ceiling effects, and is
measured on a broad response scale (0 to 100), making it ideal for illustrating
the introduced methods.

\subsection{Sample and data description}

The participants in the clinical sample of the Leuven clincial study were
screened by clinicians during the intake
in three Belgian psychiatric wards \parencite{heininga_dynamical_2019}.
Patients who met the DSM
criteria for mood disorders or borderline personality disorder during the
intake were eligible for enrollment, while those presenting with acute
psychosis, mania, addiction, or (neuro-)cognitive symptoms were excluded.
Following the screening, 90 patients enrolled in the study. Additionally, 44
control participants were matched to the clinical sample by gender and age,
resulting in a total sample size of 134.
Within the clinical sample, three patients withdrew during the baseline
assessment, two were excluded due to faulty devices, and seven were removed for
responding to less than half of the EMA measures. In the control sample, one
participant was excluded for responding to less than half of the EMA measures,
and three were removed for meeting the criteria for a current psychiatric
disorder. Consequently, the final published data set included 78 participants
in the clinical sample and 40 participants in the control sample.

During the study, all participants completed a baseline assessment, followed by
seven days of semi-random EMA assessments, with 10 equidistant assessments per
day. However, the starting date of the EMA measures varied between people.
During each assessment, participants responded to 27 questions covering
emotions, social expectancies, emotion regulation, context, and psychiatric
symptoms. This analysis focused on the item assessing momentary depressive mood
(i.e., "How depressed do you feel at the moment?") rated on a scale from 0 to
100. One additional participant was removed from the analysis for consistently
reporting a score of zero across all assessments, resulting in a final sample
of 117 participants. For a more thorough sample and data description, see
\textcite{heininga_dynamical_2019}.

The published data set was obtained from the EMOTE database
\parencite{kalokerinos_emote_nodate}. The initial study
procedure was approved by the KU Leuven Social and Societal Ethics Committee
and the KU Leuven Medical Ethics Committee. This secondary data analysis was
approved by the Ethics Review Board of the Tilburg School of Social and
Behavioral Sciences.

\subsection{Analysis Plan}

\subsubsection{Exploratorty idiographic analysis}

First, the LPR, GP, and GAM were applied to explore the idiographic
latent processes underlying the data. Each method was applied separately to the
time-series of each participant, using the same specifications as in the
simulation study (Appendix B). However, for the LPR, only local cubic
polynomials were
considered to keep the interpretation of the bandwidth consistent across
participants.
Since all participants were assessed over seven days, but not during the same
period, the time-series for each participant was centered so that the first
measurement time point served as the zero point. The LPR bandwidth, GP
lengthscale, and GAM smoothing parameter were then analyzed to assess the
wigglyness of the idiographic processes. Additionally, the GCV values produced
by each method were evaluated to determine which method provided the most
accurate interpolations. Lastly, the mean squared error was calculated for each
method and data set to estimate the expected measurement error.

\subsubsection{Multilevel analysis}

After the idiographic analysis, mixed-effects GAMs were fitted to the data to
assess the extent to which common and idiographic smooth are necessacary for
accurately modeling the data. The baseline model was a random intercept model,
where each participant's data was modelled by a person-specific flat line.
The second model fitted a random smooth, in which each participant's data
was modelled by an individual smooth function with a common smoothing parameter
through factor-smooth interactions. To determine if there was evidence of a
common non-linear trend, this model was compared to an extended model,
which combined a common non-linear smooth with individual random non-linear
deviations. These deviations were again modelled using factor-smooth
interactions with a common smothing parameter. Finally, to test
potential heterogeneity in the smoothing parameters across participants,
a fourth model was fitted, which allowed for individual smooth terms with
varying smoothing parameters.

\subsubsection{Parametric analysis}

Lastly, three parametric differential equation models were applied to explore
the data. The first model is a random-walk model, where the rate of change in
the latent depression state does not depend on its current value, such that
future values are only influenced by random perturbations in form of the
dynamic errors.
The second model is a continuous-time autoregressive model, where the
depression score reverts to an individual's mean at a rate linearly dependent
on the distance from this mean. Both the individual mean and autoregressive
effect were treated as random effects by incorporating them as time-invariant
state variables, similar to how random effects are included
in dynamic structural equation models.
The third model is the damped oscillator model discussed earlier. To adapt this
model to the data structure, a random mean was added to account for
between-person differences in the baseline level around which the depression
score oscillates. Random effects were also included for the spring constant
and damping coefficient to accommodate individual differences in oscillation
patterns. All three models included components for measurement and dynamic
error variances. Lastly, the model fit was compared between the models
using the AIC and BIC\@.

\subsection{Results}

\subsubsection{Exploratorty idiographic analysis}

First, the LPR, GP, and GAM were used to
estimate the individual latent depression processes. For the local cubic
regression, the median optimal bandwidth was 21.28 hours (\textit{IQR}: 5.52).
For the GP, the median optimal length scale was 22.57 standard deviations
(\textit{IQR}: 15.09). Lastly, for the GAMs, the median optimal smoothing
parameter was $8.18*10^9$ (\textit{IQR}: $1.76*10^{10}$). Unfortunately, these
three measures of wiggliness are not only on different scales, but there is
also only a moderate correlation between the bandwidth and lengthscale
parameters (\textit{r} = 0.33). Further, the smoothing parameter of the GAMs
shows
little to no correlation with the other two measures (bandwidth: \textit{r} =
-0.03; length scale: \textit{r} = -0.08). This discrepancy arises because,
while all three parameters reflect the wiggliness of the estimate, they capture
different aspects of it. For example, in data with a linear trend, the
bandwidth of the local cubic regression and the smoothing parameter of the GAMs
would theoretically be infinite, while the length scale parameter of the GP
would have a finite value. Additionally, the interpretation of each
wiggliness parameter depends in the model configurations chosen and would
change for different configurations of these methods.

Because of this, there is not much value in interpreting the absolute values
of these parameters. Instead, we explored the range of functional behaviours
inferred by the most extreme values of each parameters. Figuer
\ref{fig:dem_smooth} shows
the ten least and most wiggly processes inferred by each method. This figure
reveals considerably heterogeneity in the functional behaviour inferred by
each method. Most interestingly, the least wiggly processes inferred by both
the GPs and the GAMs are linear trends, indicating the absence of any
dynamic errors for these individuals. In contrast to this, the processes
with the highest inferred wigglyness, display either large dynamic errors
around their respective person means or in addition to this a different
non-linear dynamic.

\begin{figure}[!ht]
  \caption{The ten least and most wiggly idiographic latent depression
    processes as inferred by the LPRs, GPs, and GAMs}
  \fitfigure{demonstration_smooths.png}
  \label{fig:dem_smooth}
\end{figure}

Lastly, a cross-validation was conducted using the generalized cross-validation
criterion to investigate which method predicted the latent processes most
accurately. The median GCV for the GAMs was 125.29 (\textit{IQR}: 201.04),
for the GP it was 248.27 (\textit{IQR}: 578.00), and for the LPR it was
131.57 (\textit{IQR}: 213.73). In addition to this, the mean squared error
was calculated between the predictions generated by each method and the data.
Here the median MSE of the GAM was 114.04 (\textit{IQR}: 171.59),
for the GP it was 197.54 (\textit{IQR}: 388.40), and for the LPR it was
101.74 (\textit{IQR}: 153.77). Together with the GCV this indicates that
the GAM inferred the latent processes most accurately, whereas the LPR
slightly overfit the data and the GPs tended to underfit the data.

\subsubsection{Multilevel analysis}

First, the baseline model with only the random intercepts had an
adjusted $R^2$ of 0.75 (\textit{GCV} = 231). Extending the model to include
random smooths for each individual with a common smoothing penalty increased
the adjusted $R^2$ to 0.81 (\textit{GCV} = 194.89). However, adding a common
smooth to this model did not change the model fit.
Lastly, using person-specific smooth terms for the random smooth increased
the adjusted $R^2$ further to 0.82 (\textit{GCV} = 184.29). Table
\ref{tab:ic_tab} compares the four models using the AIC and BIC. The AIC
indicates the most complex model, providing
evidence for the necessacity of individual smooth parameters. However,
the BIC, which given the sample size uses a heavier penalty, indicates
the random intercpet model as the best fitting model, highlighting that
the majority of the variance in the data is due to mean level
differences. Overall, there is conflicting evidence regarding which model
fits the data best.

\begin{table}[htbp]
  \vspace*{2em}
  \begin{threeparttable}
    \caption{Model information criteria for four mixed effects GAMs}
    \label{tab:ic_tab}
    \begin{tabular}{@{}lrrr@{}} \toprule
      Model                                 & Degrees of freedom & AIC      &
      BIC
      \\ \midrule
      Random intercept                      & 117.3599           & 58997.31 &
      59803.73
      \\
      Random smooth w. common penalty       & 708.5276           & 57712.79 &
      62581.35
      \\
      Common smooth w. deviations           & 708.0516           & 57712.76 &
      62578.04
      \\
      Random smooth w. individual penalties & 625.9867           & 57331.22 &
      61632.60
      \\ \midrule
    \end{tabular}
  \end{threeparttable}
\end{table}

\subsubsection{Parametric analysis}

\textit{Not working yet}

\section{Discussion}

Both the simulation and empirical example demonstrated that GAMs inferred the
latent processes more accurately than the LPR and GP in terms of MSE, GCV,
and confidence interval coverage across all conditions. Additionally, the GAMs
were nearly as accurate as the true data-generating parametric models in the
simulation and outperformed the tested parametric models in predicting the
empirical data based on the GCV\@. This finding was unexpected, as we
anticipated
that the smooth estimates produced by GAMs might not be optimally suited for
inferring the rough (i.e., non-differentiable) processes that were simulated.
However, the LPR and the default GP specifications also produce smooth
estimates, causing similar misspecifications as the GAMs. This may suggests
that the accuracy of the GAMs was least affected by the roughness of the latent
process. However, another factor that may have influenced the accuracy of
LPR and GP methods is that both assume constant wiggliness, as defined by their

bandwidth and lengthscale parameters respectively, which was violated for the
processes tested.

Importantly, there are several theoretical reasons that indicate that the
observed results may only be due to the specific configurations
that were used for each method, rather than by the general methods
themselves. The configurations for each method were chosen to reflect
how each method is commonly applied in its most basic form and not too
optimally infer the types of processes simulated. Thus, it is possible
that different configurations and extensions might improve the perfromance
of the LPR and GP\@. Specifically, Fan et al. () showed that the LPR is
minmax efficient for certain processes and using extensions for variable
bandwidth and polynomial selection as well as for bias correction
might improve their inference accuracy.

- Adaptiations for the other two methods are available that might equipped
them to deal better with this

- Against expectation the cusp-catastrophe was inferred best
- Due to being more resistant to external perturbations
- Higher gradient towards the attractor
- Point at figure with dynamic errors
- Rerunning the simulation with much lower dynamic error variances showed
that then the cusp model was inferred better.

- For the oter three simulation conditions, sampling at a higher frequency is
generally desirable
- Here choices may be influenced by prior knowledge about the variability
of certain constructs
- Sampling for longer periods of time is a design choice and if the
functional behaviour of the latent process is expected to change over the
sampling period that should be taken into account
-Lastly, reducing dynamic errors is generally advisable.

- Here we focussed on inferring non-liear trends but the possibilities of
these methods are rather more interesting
- Estimate non-linear autoregressive functions
- Estimate state-space models or differential equation models
non-parametrically
- Infer input forces to differential equation models
- Combine everything togther to test partial theories

- Limitations
- Only few processes considered
- Processes with constant wigglyness in the sense of the LPR or GP may change
the picture
- Focus mostly on univariate singe subject desing with iid gaussian errors

- There are many ways to extend these methods
- Multilevel extensions are somewhat already available
- Measurement models are somewhat already available
- Multivariate models run into an issue of

\section{Conclusion}

\printbibliography[]

\end{document}